Abstract: In this paper, we examine attributes predictive of account suspension in a pro-People's Republic of China (PRC) information operation on Twitter. We find, contrary to previous research, that in this campaign, including text as a feature, across a variety of BERT-based models and architectures, resulted in poor or decreased predictive performance. We find that the account metadata features played a much stronger role in account suspension prediction than the text of tweets. This case-study flags some of the potential limitations of AI systems in detecting malign activity on Twitter and highlights the importance of metadata in identifying influence operations.

\section{Introduction}

Twitter users “tweet” a staggering 500 million posts a day, each of which can now be up to 280 characters \cite{twitterstats}. While Twitter is protected from liability for the content users post through Section 230 of the 1996 Communications Decency Act, Twitter voluntarily elects to moderate certain harmful categories of content. Though Twitter’s suspicious behavior algorithms are not public, Twitter does document its terms of service. According to “The Twitter Rules,” Twitter regulates content that threatens public safety.\footnote{This includes threats of violence, terrorism/extremism, targeted abuse/harassment, suicide promotion, child sexual exploitation, graphic violence or adult content, the publishing of private information, and illegal or regulated goods or services.} Twitter also reserves the right to regulate “hateful conduct,” a catch-all term aimed at limiting the promotion of violence, threats, or harassment towards others \cite{twitterrules}.

The Twitter Rules also contain provisions aimed at guaranteeing the authenticity of conversation on Twitter. Specifically, the Twitter Rules state that one may not use Twitter’s services “in a manner intended to artificially amplify or suppress information or engage in behavior that manipulates or disrupts people’s experience on Twitter”. The rules also apply a terms of service violation to the posting of content aimed at interfering in election or civic processes, actions constituting impersonation with intent to mislead; the sharing of synthetic or manipulated media likely to cause harm; and the posting of any content that constitutes a copyright or trademark infringement. Actions that constitute terms of service violations are not linked solely to tweet content, but also to inauthentic engagements, coordinated activity, multiple account management, artificial metric inflation, and profile obfuscation or theft \cite{twitterplatrules}.  

While Twitter releases transparency reports and makes disinformation campaign datasets available to researchers, the reasons for account suspensions are not always clear, partially because not all user metadata, for example registration email, is made publicly available. The rate at which Twitter suspends accounts appears to be growing with periodic suspension campaigns netting up to 70 million accounts \cite{wapotwitter}. Cui \cite{cui} found that over a five year period about 14\% of accounts were suspended for reasons not linked explicitly to Twitter’s Rules. Often, Twitter will suspend accounts simply because they have been inactive for a long period of time \cite{inactive}. Accounts that posted disinformation regarding the U.S. Presidential Election in 2020 were subject to a mix of temporary account locks, account suspensions, tweet deletions, and content labeling, with no clear rule pattern to explain the outcome. Perhaps this inconsistency partly explains why, 60\% of accounts that are eventually suspended are active for two years before suspension according to Chowdhury et al. \cite{chowdhury}.

Over the past two years, Twitter has been faced with the challenge of identifying and acting on suspicious networks of coordinated actors acting to amplify pro-People's Republic of China (PRC)\footnote{PRC is used throughout this paper to refer to the government of the People's Republic of China and not to China as a whole or to the Chinese people.} messaging and suppress any narrative critical of Beijing’s policies. Despite Twitter being banned in China, there are now close to 500 Chinese state media, diplomatic missions, and other government and state organizations with accounts on the platform. Significant surges in PRC Twitter account registration coincided with the Hong Kong protests in Summer 2019 and the COVID-19 pandemic outbreak at the start of 2020 \cite{zengj}. Alongside the registration of these official accounts came the rise of a network of pro-PRC accounts dedicated to retweeting posts from official PRC accounts, amplifying pro-PRC messaging, and attacking posts critical towards PRC positions.

Twitter suspended thousands of accounts it claims were linked to PRC information operations (IO) and violated its terms of service in 2020, including 23,000 “core” accounts and 150,000 “amplifier” accounts \cite{twittersafety}.  According to Stanford Internet Observatory’s Renée DiResta, Beijing responded to the massive Twitter takedown campaign by immediately creating new accounts to replace those suspended \cite{accremov1}.  This was not the first time Twitter took such action towards suspicious PRC-linked campaigns on the platform, with Twitter in August 2019 removing close to 1,000 accounts and suspending another 200,000 accounts targeting the pro-democracy movement in Hong Kong  \cite{accremov2}.

In disinformation campaigns, suspension gives attackers real-time feedback about the quality of their evasion tactics. Once accounts are suspended, their data are no longer accessible online or through APIs. We hope that by drawing attention to the characteristics associated with the time up until suspensions, researchers will be better able to anticipate rational adjustments that the attacker will make to the tactics and procedures of their campaigns.

In this study, we develop a model to predict the likelihood of an account in a PRC-linked IO campaign being suspended. We compare BERT-based text-only classifiers, metadata classifiers with word embeddings extracted from BERT, and metadata-only classifiers that only incorporate account behavior and characteristics. This paper specifically evaluates the performance of two different fine-tuned BERT models - base multilingual cased BERT (M-BERT) and Language agnostic BERT Sentence Embeddings (LaBSE). 

The key findings of this paper are two-fold. First, we show that fine-tuned BERT-based models provide limited utility in classifying the likelihood that tweets come from accounts that will eventually be suspended and that an account will be suspended.  Second, in contrast to the findings of Volkova and Bell \cite{volko}, we find that account features played a stronger role in account suspension prediction than did the text of tweets, and the text of tweets even decreased predictive capacity in several of the models evaluated. This paper conducts an ablation study evaluating 36 different models.
